//
// Created by artin on 04/6/2017.
//
#include <cstdlib>
#include <opencv2/core/mat.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/opencv.hpp>
#include "VideoProcessing.h"
#include "../ImageBasicOperations.h"
#include "../models/ChessSquareMatrix.h"
#include "EdgeProcessing.h"
#include "MotionProcessing.h"
#include "MogLearningSpeed.h"

using namespace cv;
using namespace std;

// Mog mask generated by MOG2 method
Mat fgMaskMOG2;
// Current frame
Mat frame;
// Size to resize the frames
Size size(800, 600);

bool vitualizeWithPieces = true;

/**
 * Counter used to remap the board in case it was moved (the square were identified )
 */
int remapBoardCounter = 0;
int remapTimer = 30 * 60 * 2; // 30 frames * 60 secs * 2  = every 2 mins

int mogQueueSize = 100;
std::queue<cv::Mat> queueOfMogs;


/**
 * Function used to keep a queue of {@link mogQueueSize} mog masks
 * @param mog The mog mask that will be placed in the queue
 */
void addToQueueMog(cv::Mat &mog) {
    if (queueOfMogs.size() == mogQueueSize) {
        queueOfMogs.pop();
    }
    queueOfMogs.push(mog);
}

/**
 * Function used to take the frame containing the chess table and make a virtual representation of it
 * NOTE now it runs on a image
 * @param squareMatrix
 */
void virtualizeChessTable(ChessSquareMatrix *squareMatrix) {
    if (remapBoardCounter == 0) {
        remapBoardCounter = remapTimer;

        // Remap the board, in case it has moved
        Mat src = imagePreparation::readImage(
                "D:\\Facultate\\c++Project\\opencv_c-c-\\edgeDetection\\images\\new_squares\\img1.jpg"); //read the image
        delete squareMatrix;
        resize(src, src, size);
        squareMatrix = new ChessSquareMatrix(8);
        EdgeProcessing::startProcess(src, *squareMatrix,vitualizeWithPieces);
        // TODO , call the function to detect edges again
    } else {
        remapBoardCounter--;
    }
}

void changeColorSpace(cv::Mat &frame){
    cv::Mat lab_image;
    cv::cvtColor(frame, lab_image, CV_BGR2Lab);

    // Extract the L channel
    std::vector<cv::Mat> lab_planes(3);
    cv::split(lab_image, lab_planes);  // now we have the L image in lab_planes[0]

    // apply the CLAHE algorithm to the L channel
    cv::Ptr<cv::CLAHE> clahe = cv::createCLAHE();
    clahe->setClipLimit(4);
    cv::Mat dst;
    clahe->apply(lab_planes[0], dst);

    // Merge the the color planes back into an Lab image
    dst.copyTo(lab_planes[0]);
    cv::merge(lab_planes, lab_image);

    // convert back to RGB
    cv::Mat image_clahe;
    cv::cvtColor(lab_image, frame, CV_Lab2BGR);
}

void VideoProcessing::watchTheVideo(char *videoFilename) {
    //create the capture object
    VideoCapture capture(videoFilename);
    if (!capture.isOpened()) {
        //error in opening the video input
        cerr << "Unable to open video file: " << videoFilename << endl;
        exit(EXIT_FAILURE);
    }
    mogLearningSpeed = 0.05;

    // Chess table square matrix
    ChessSquareMatrix *squareMatrix = NULL;

    // Background subtract object
    Ptr<BackgroundSubtractorMOG2> mog2MotionDetection = createBackgroundSubtractorMOG2();
//    mog2MotionDetection->setHistory(20);
//    mog2MotionDetection->setShadowThreshold(0.01);
    mog2MotionDetection->setDetectShadows(false);
//    mog2MotionDetection->setShadowValue(255);
//    mog2MotionDetection->setBackgroundRatio(0.8);

    //read input data. ESC or 'q' for quitting
    char keyboard = 0;

    while (keyboard != 'q' && keyboard != 27) {
        //read the current frame
        if (!capture.read(frame)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            exit(EXIT_FAILURE);
        }

        resize(frame, frame, size);

//        virtualizeChessTable(squareMatrix); // THIS IS WORKING

//        changeColorSpace(frame);


        cv::cvtColor(frame, frame, COLOR_RGB2GRAY);
//        equalizeHist( frame, frame );

        GaussianBlur(frame, frame, Size(3, 3),0, 0);

        Mat cannyMat;

//        int lowThreshold = 50; // TODO THIS SHOULD BE AUTOMATIZED, SEARCH INTERNET
//        Canny(frame, cannyMat, lowThreshold, lowThreshold * 3, 3);
//        imshow("Canny mat", cannyMat);

//        medianBlur ( frame, frame, 5 );
//
        // Update the background model
        mog2MotionDetection->apply(frame, fgMaskMOG2, mogLearningSpeed);

        fgMaskMOG2 = imagePreparation::erosionImage(fgMaskMOG2, 2, 2);
        fgMaskMOG2 = imagePreparation::dilationImage(fgMaskMOG2, 2,1 );
//        imshow("before operation", fgMaskMOG2);


        addToQueueMog(fgMaskMOG2);

        //get the frame number and write it on the current frame
        stringstream ss;
        rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
                  cv::Scalar(255, 255, 255), -1);
        ss << capture.get(CAP_PROP_POS_FRAMES);
        string frameNumberString = ss.str();


        // If there was motion, here we will store the mog mask
        Mat movedPiece;

        // If there was motion
        if (MotionProcessing::watchMotion(frame, fgMaskMOG2, frameNumberString.c_str(), movedPiece, mog2MotionDetection)) {
//            imshow("Motion result",movedPiece);
//            // Extract the contour of the extracted piece
//            PieceContour extractedPieceContour = ImageDB::getContourFromMat(movedPiece);
//            // Try to see if we can identify it;
//            PieceType pieceType = ImageDB::matchChessPieces(extractedPieceContour); // TODO this is not 100% accurate
        }

        putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
                FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
        //show the current frame and the fg masks
        keyboard = (char) waitKey(100);

        imshow("Frame", frame);
        imshow("FG Mask MOG 2", fgMaskMOG2);
        //get the input from the keyboard
    }
    //delete capture object
    capture.release();
}
